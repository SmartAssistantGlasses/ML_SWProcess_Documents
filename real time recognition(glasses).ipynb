{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWv0PJMqaX7R"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "veENZG4SagcO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gtts\n",
    "import time\n",
    "import pickle\n",
    "import miniaudio\n",
    "from PIL import Image\n",
    "from mutagen.mp3 import MP3\n",
    "from matplotlib import pyplot\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "from numpy import asarray,expand_dims\n",
    "from sklearn.preprocessing import LabelEncoder,Normalizer,LabelEncoder,Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('F:\\Graduation Project\\Computer Vision\\Face Recognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a face embedding for each face in the dataset using facenet\n",
    "def get_embedding(model_, face_pixels_):\n",
    "\t# scale pixel values\n",
    "\tface_pixels_ = face_pixels_.astype('float32')\n",
    "\t# standardize pixel values across channels (global)\n",
    "\tmean_, std_ = face_pixels_.mean(), face_pixels_.std()\n",
    "\tface_pixels_ = (face_pixels_ - mean_) / std_\n",
    "\t# transform face into one sample\n",
    "\tsamples_ = expand_dims(face_pixels_, axis=0)\n",
    "\t# make prediction to get embedding\n",
    "\tyhat_ = model_.predict(samples_)\n",
    "\treturn yhat_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# load the facenet model to get embeddings from detected face\n",
    "facenet_model = load_model('facenet_keras.h5')\n",
    "# load svc model to classify the embeddings\n",
    "pickled_model55 = pickle.load(open('model_svc.pkl', 'rb'))\n",
    "labels=['Alaa Samir','aravind','billgates','messi','ronaldo','stevejob','sundarpichai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Alaa Samir\n",
      " Alaa Samir\n",
      " ronaldo\n",
      " ronaldo\n",
      " ronaldo\n",
      " ronaldo\n",
      " messi\n",
      " messi\n",
      " messi\n",
      " messi\n",
      " messi\n",
      " ronaldo\n",
      " ronaldo\n",
      " ronaldo\n",
      " ronaldo\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " messi\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " messi\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " billgates\n",
      " messi\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " messi\n",
      " messi\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " billgates\n",
      " messi\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " stevejob\n",
      " messi\n",
      " messi\n",
      " Alaa Samir\n",
      " messi\n",
      " stevejob\n",
      " stevejob\n",
      " stevejob\n",
      " stevejob\n",
      " stevejob\n",
      " messi\n",
      " stevejob\n",
      " stevejob\n",
      " stevejob\n",
      " stevejob\n",
      " stevejob\n",
      " stevejob\n",
      " stevejob\n",
      " messi\n",
      " messi\n",
      " messi\n",
      " ronaldo\n",
      " messi\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " messi\n",
      " ronaldo\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " Alaa Samir\n",
      " ronaldo\n",
      " messi\n",
      " billgates\n",
      " ronaldo\n",
      " ronaldo\n",
      " Alaa Samir\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "counter=0\n",
    "while(True):\n",
    "    \n",
    "    ret, frame_real = vid.read()\n",
    "    # crop image to get face only\n",
    "    pixels_ = asarray(frame_real)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results_ = detector.detect_faces(pixels_)\n",
    "\n",
    "    while len(results_)== 0 :\n",
    "        _, frame_real = vid.read()\n",
    "        pixels_ = asarray(frame_real)\n",
    "        results_ = detector.detect_faces(pixels_)\n",
    "    \n",
    "    x1_, y1_, width_, height_ = results_[0]['box'] \n",
    "    x1_, y1_ = abs(x1_), abs(y1_)\n",
    "    x2_, y2_ = x1_ + width_, y1_ + height_\n",
    "    # extract the face\n",
    "    face_ = pixels_[y1_:y2_, x1_:x2_]\n",
    "    # resize pixels to the model size\n",
    "    image_ = Image.fromarray(face_)\n",
    "    required_size_=(160,160)\n",
    "    image_ = image_.resize(required_size_)\n",
    "    face_array_from_image = asarray(image_)    \n",
    "    # show detected face\n",
    "    cv2.imshow('Detected face', face_array_from_image)\n",
    "    # get embedding from detected face\n",
    "    face_embedding_real=get_embedding(facenet_model,face_array_from_image)\n",
    "    # convert embedding to array\n",
    "    face_embedding = asarray(face_embedding_real)\n",
    "    # normalize the image\n",
    "    in_encoder = Normalizer(norm='l2')\n",
    "    face_embedding_real=in_encoder.transform(face_embedding_real.reshape(1,-1))\n",
    "    # convert image array to one vector\n",
    "    samples_real = expand_dims(face_embedding_real.reshape(-1,), axis=0)\n",
    "    # make predictions\n",
    "    yhat_class_real = pickled_model55.predict(samples_real)\n",
    "    yhat_prob_real = pickled_model55.predict_proba(samples_real)\n",
    "    \n",
    "    class_index_real = yhat_class_real[0]\n",
    "    class_probability_real = yhat_prob_real[0,class_index_real] * 100\n",
    "    print(f' {labels[yhat_class_real[0]]}')\n",
    "    \n",
    "    tts=gtts.gTTS(f' {labels[yhat_class_real[0]]}',lang=\"ar\")\n",
    "    counter+=1\n",
    "    tts.save('alaa'+f'{counter}.mp3')\n",
    "    file='alaa'+f'{counter}.mp3'\n",
    "    audio = MP3(file)\n",
    "    length=audio.info.length\n",
    "    stream = miniaudio.stream_file(file)\n",
    "    with miniaudio.PlaybackDevice() as device:\n",
    "        device.start(stream)\n",
    "        time.sleep(length)\n",
    "    if counter > 1:              \n",
    "        os.remove('alaa'+f'{counter-1}.mp3')\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
